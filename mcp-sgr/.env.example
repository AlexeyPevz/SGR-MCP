# MCP-SGR Environment Configuration Example
# Copy this file to .env and update with your values

# LLM Provider Configuration
# Available backends: ollama, openrouter, vllm, custom
LLM_BACKENDS=ollama
ROUTER_DEFAULT_BACKEND=ollama

# Ollama Configuration (for local models)
OLLAMA_HOST=http://localhost:11434
OLLAMA_DEFAULT_MODEL=llama3.1:8b

# OpenRouter Configuration (optional)
# Get your API key from https://openrouter.ai/
OPENROUTER_API_KEY=
OPENROUTER_DEFAULT_MODEL=meta-llama/llama-3.1-8b-instruct

# Custom LLM Configuration (optional)
CUSTOM_LLM_URL=

# SGR Configuration
SGR_BUDGET_DEPTH=lite              # none|lite|full
SGR_PRE_ANALYSIS=auto              # auto|always|never
SGR_POST_ANALYSIS=lite             # lite|full
SGR_SAMPLE_RATE=0.5                # 0.0â€“1.0 (fraction of requests with full mode)

# Cache Configuration
CACHE_ENABLED=true
CACHE_STORE=sqlite:///./data/cache.db
CACHE_TTL=3600                     # Cache TTL in seconds

# Tracing Configuration
TRACE_ENABLED=true
TRACE_STORE=sqlite:///./data/traces.db
PII_REDACT=true

# HTTP Server Configuration
HTTP_ENABLED=true
HTTP_PORT=8080
HTTP_HOST=0.0.0.0
HTTP_AUTH_TOKEN=                   # Optional API auth token
HTTP_REQUIRE_AUTH=false

# OpenTelemetry Configuration (optional)
OTEL_ENABLED=false
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317

# Rate Limiting
RATE_LIMIT_ENABLED=true
RATE_LIMIT_REQUESTS_PER_MINUTE=60

# Logging
LOG_LEVEL=INFO
LOG_FILE=./logs/mcp-sgr.log