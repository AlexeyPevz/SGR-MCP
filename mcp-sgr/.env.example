# LLM Backends Configuration
LLM_BACKENDS=ollama,openrouter
OLLAMA_HOST=http://localhost:11434
OPENROUTER_API_KEY=your-openrouter-api-key
CUSTOM_LLM_URL=https://your-custom-llm-endpoint.com

# Default model for each backend
OLLAMA_DEFAULT_MODEL=llama3.1:8b
OPENROUTER_DEFAULT_MODEL=meta-llama/llama-3.1-8b-instruct

# SGR Configuration
SGR_BUDGET_DEPTH=lite              # none|lite|full
SGR_PRE_ANALYSIS=auto              # auto|always|never
SGR_POST_ANALYSIS=lite             # lite|full
SGR_SAMPLE_RATE=0.5                # 0.0-1.0 (fraction of requests with full mode)

# Cache Configuration
CACHE_ENABLED=true
CACHE_STORE=sqlite:///./data/cache.db
CACHE_TTL_SECONDS=3600

# Trace Configuration
TRACE_ENABLED=true
TRACE_STORE=sqlite:///./data/traces.db
TRACE_RETENTION_DAYS=7

# Privacy
PII_REDACT=true
PII_PATTERNS=email,phone,ssn,credit_card

# HTTP Facade Configuration
HTTP_ENABLED=true
HTTP_PORT=8080
HTTP_HOST=0.0.0.0
HTTP_AUTH_TOKEN=optional-security-token

# Telemetry
OTEL_ENABLED=false
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317
OTEL_SERVICE_NAME=mcp-sgr

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json
LOG_FILE=./logs/mcp-sgr.log

# Router Policy
ROUTER_POLICY_FILE=./router_policy.yaml
ROUTER_DEFAULT_BACKEND=ollama

# Development
DEBUG=false
RELOAD=true