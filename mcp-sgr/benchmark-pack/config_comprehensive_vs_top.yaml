name: "Comprehensive SGR Benchmark: Budget vs Top Models"
api_key_env: "OPENROUTER_API_KEY"
output_dir: "reports"
parallel_workers: 3
max_retries: 2
timeout: 120

# Include top models + best budget models
models:
  # Top-tier models (expensive)
  - name: "GPT-4o"
    id: "openai/gpt-4o"
    cost_per_1k_input: 2.5
    cost_per_1k_output: 10.0
    supports_json: true
    
  - name: "Claude-3.5-Sonnet" 
    id: "anthropic/claude-3.5-sonnet"
    cost_per_1k_input: 3.0
    cost_per_1k_output: 15.0
    supports_json: true
    
  - name: "GPT-4-Turbo"
    id: "openai/gpt-4-turbo"
    cost_per_1k_input: 10.0
    cost_per_1k_output: 30.0
    supports_json: true
    
  # Mid-tier models
  - name: "GPT-3.5-Turbo"
    id: "openai/gpt-3.5-turbo"
    cost_per_1k_input: 0.5
    cost_per_1k_output: 1.5
    supports_json: true
    
  - name: "Claude-3-Haiku"
    id: "anthropic/claude-3-haiku"
    cost_per_1k_input: 0.25
    cost_per_1k_output: 1.25
    supports_json: true
    
  # Budget models (free/cheap)
  - name: "Mistral-7B-Free"
    id: "mistralai/mistral-7b-instruct:free"
    cost_per_1k_input: 0.0
    cost_per_1k_output: 0.0
    supports_json: true
    
  - name: "Ministral-8B"
    id: "ministral/ministral-8b-2410"
    cost_per_1k_input: 0.02
    cost_per_1k_output: 0.02
    supports_json: true
    
  - name: "DeepSeek-Chat"
    id: "deepseek/deepseek-chat"
    cost_per_1k_input: 0.14
    cost_per_1k_output: 0.28
    supports_json: true
    
  - name: "Qwen-2.5-7B"
    id: "qwen/qwen-2.5-7b-instruct"
    cost_per_1k_input: 0.15
    cost_per_1k_output: 0.15
    supports_json: true
    
  - name: "Qwen-2.5-72B"
    id: "qwen/qwen-2.5-72b-instruct"
    cost_per_1k_input: 0.9
    cost_per_1k_output: 0.9
    supports_json: true

# Test all categories with focus on coding
test_categories:
  - name: "codegen"
    weight: 2.0  # Double weight for code tasks
  - name: "rag"
    weight: 1.0
  - name: "summarization"
    weight: 1.0
  - name: "planning"
    weight: 1.0
  - name: "data"
    weight: 1.0
  - name: "agent"
    weight: 1.0

# Comprehensive task selection (40 tasks total)
tasks:
  # Code generation - 12 tasks (focus area)
  - "code_cli_converter_001"
  - "code_string_utils_002"  
  - "code_rest_api_003"
  - "code_graph_algos_004"
  - "code_jwt_auth_005"
  - "code_bug_fix_006"
  - "code_sql_query_007"
  - "code_react_component_008"
  - "code_python_class_009"
  - "code_test_generation_010"
  - "code_cli_converter_001"  # Repeat for more data
  - "code_rest_api_003"       # Repeat for more data
  
  # RAG QA - 6 tasks
  - "rag_factual_qa_001"
  - "rag_multidoc_synthesis_002"
  - "rag_conflicting_sources_003"
  - "rag_time_sensitive_004"
  - "rag_citation_required_005"
  - "rag_noise_filtering_006"
  
  # Summarization - 6 tasks
  - "sum_report_001"
  - "sum_technical_doc_002"
  - "sum_meeting_notes_003"
  - "sum_research_paper_004"
  - "sum_comparative_docs_005"
  - "sum_policy_brief_006"
  
  # Planning - 6 tasks
  - "plan_pwa_architecture_001"
  - "plan_ml_pipeline_002"
  - "plan_migration_strategy_003"
  - "plan_product_roadmap_004"
  - "plan_team_scaling_005"
  - "plan_tech_stack_006"
  
  # Data ETL - 5 tasks
  - "data_email_validation_001"
  - "data_date_normalization_002"
  - "data_csv_to_json_003"
  - "data_fuzzy_matching_004"
  - "data_phone_cleanup_005"
  
  # Agent workflow - 5 tasks
  - "agent_bug_to_patch_001"
  - "agent_code_review_002"
  - "agent_test_debug_003"
  - "agent_rag_chain_004"
  - "agent_data_pipeline_005"

# All SGR modes for comparison
sgr_modes:
  - "off"
  - "lite"
  - "full"

# Experiment settings
experiment:
  runs_per_task: 2  # Multiple runs for consistency
  max_tokens: 2000
  temperature: 0.7
  save_artifacts: true
  
# Cost limits
cost_limits:
  total_budget: 5.0  # $5 total budget
  per_model_limit: 1.0
  abort_on_limit: true