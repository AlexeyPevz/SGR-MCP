#!/usr/bin/env python3
"""
–ê–¥–∞–ø—Ç–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å YandexGPT API –≤ —Å–∏—Å—Ç–µ–º–µ –±–µ–Ω—á–º–∞—Ä–∫–æ–≤
"""

import json
import urllib.request
import urllib.error
import os
import time
from typing import Dict, List, Optional

class YandexGPTAdapter:
    """–ê–¥–∞–ø—Ç–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å YandexGPT API"""
    
    def __init__(self, api_key: Optional[str] = None, folder_id: Optional[str] = None):
        self.api_key = api_key or os.environ.get("YANDEX_API_KEY")
        self.folder_id = folder_id or os.environ.get("YANDEX_FOLDER_ID")
        self.base_url = "https://llm.api.cloud.yandex.net/foundationModels/v1/completion"
        
    def call_model(self, 
                   messages: List[Dict[str, str]], 
                   model: str = "yandexgpt-lite",
                   temperature: float = 0.6,
                   max_tokens: int = 1000,
                   sgr_mode: Optional[str] = None) -> Dict:
        """
        –í—ã–∑–æ–≤ YandexGPT API
        
        Args:
            messages: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π —á–∞—Ç–∞
            model: –ú–æ–¥–µ–ª—å (yandexgpt-lite –∏–ª–∏ yandexgpt)
            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            max_tokens: –ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤
            sgr_mode: –†–µ–∂–∏–º SGR (–¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å—Ö–µ–º—ã)
            
        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º
        """
        
        if not self.api_key or not self.folder_id:
            return {
                "success": False,
                "error": "Missing YANDEX_API_KEY or YANDEX_FOLDER_ID"
            }
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è YandexGPT
        prompt = self._prepare_prompt(messages, sgr_mode)
        
        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞
        model_uri = f"gpt://{self.folder_id}/{model}/latest"
        
        request_data = {
            "modelUri": model_uri,
            "completionOptions": {
                "stream": False,
                "temperature": temperature,
                "maxTokens": max_tokens
            },
            "messages": [
                {
                    "role": "user",
                    "text": prompt
                }
            ]
        }
        
        # –°–æ–∑–¥–∞–Ω–∏–µ HTTP –∑–∞–ø—Ä–æ—Å–∞
        req = urllib.request.Request(
            self.base_url,
            headers={
                "Authorization": f"Api-Key {self.api_key}",
                "Content-Type": "application/json",
                "x-folder-id": self.folder_id
            },
            data=json.dumps(request_data).encode('utf-8')
        )
        
        try:
            start_time = time.time()
            response = urllib.request.urlopen(req)
            result = json.loads(response.read().decode('utf-8'))
            latency = time.time() - start_time
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞
            if "result" in result and "alternatives" in result["result"]:
                content = result["result"]["alternatives"][0]["message"]["text"]
                tokens_used = result["result"]["usage"]["totalTokens"]
                
                return {
                    "success": True,
                    "content": content,
                    "model": model,
                    "latency": latency,
                    "tokens_used": tokens_used,
                    "cost": self._calculate_cost(tokens_used, model)
                }
            else:
                return {
                    "success": False,
                    "error": "Unexpected response format"
                }
                
        except urllib.error.HTTPError as e:
            error_data = e.read().decode('utf-8')
            return {
                "success": False,
                "error": f"HTTP {e.code}: {error_data}"
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }
    
    def _prepare_prompt(self, messages: List[Dict[str, str]], sgr_mode: Optional[str]) -> str:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–æ–º–ø—Ç–∞ —Å —É—á–µ—Ç–æ–º SGR"""
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_message = ""
        for msg in reversed(messages):
            if msg["role"] == "user":
                user_message = msg["content"]
                break
        
        # –î–æ–±–∞–≤–ª—è–µ–º SGR —Å—Ö–µ–º—É –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if sgr_mode == "lite":
            prompt = f"""{user_message}

–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π—Ç–µ –≤–∞—à –æ—Ç–≤–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
{{
  "task_understanding": "—á—Ç–æ –Ω—É–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å",
  "solution": "—Ä–µ—à–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏"
}}"""
        elif sgr_mode == "full":
            prompt = f"""{user_message}

–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π—Ç–µ –≤–∞—à –æ—Ç–≤–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
{{
  "requirements_analysis": "–∞–Ω–∞–ª–∏–∑ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π",
  "approach": "–ø–æ–¥—Ö–æ–¥ –∫ —Ä–µ—à–µ–Ω–∏—é",
  "implementation": "—Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è",
  "validation": "–ø—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ—à–µ–Ω–∏—è"
}}"""
        else:
            prompt = user_message
        
        return prompt
    
    def _calculate_cost(self, tokens: int, model: str) -> float:
        """–†–∞—Å—á–µ—Ç —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –∑–∞–ø—Ä–æ—Å–∞"""
        
        # –ü—Ä–∏–º–µ—Ä–Ω—ã–µ —Ü–µ–Ω—ã –≤ –¥–æ–ª–ª–∞—Ä–∞—Ö
        costs = {
            "yandexgpt-lite": 0.002,  # $0.002 –∑–∞ 1k —Ç–æ–∫–µ–Ω–æ–≤
            "yandexgpt": 0.02         # $0.02 –∑–∞ 1k —Ç–æ–∫–µ–Ω–æ–≤
        }
        
        cost_per_1k = costs.get(model, 0.002)
        return (tokens / 1000) * cost_per_1k


def test_yandex_gpt():
    """–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç YandexGPT"""
    
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ YandexGPT...")
    
    adapter = YandexGPTAdapter()
    
    # –¢–µ—Å—Ç –±–µ–∑ SGR
    print("\n1Ô∏è‚É£ –¢–µ—Å—Ç –ë–ï–ó SGR:")
    result = adapter.call_model(
        messages=[{"role": "user", "content": "–ù–∞–ø–∏—à–∏ —Ñ—É–Ω–∫—Ü–∏—é –Ω–∞ Python –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —á–µ—Ç–Ω–æ—Å—Ç–∏ —á–∏—Å–ª–∞"}],
        model="yandexgpt-lite",
        sgr_mode=None
    )
    
    if result["success"]:
        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ! –õ–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å: {result['latency']:.2f}s")
        print(f"–û—Ç–≤–µ—Ç: {result['content'][:200]}...")
    else:
        print(f"‚ùå –û—à–∏–±–∫–∞: {result['error']}")
    
    # –¢–µ—Å—Ç —Å SGR-lite
    print("\n2Ô∏è‚É£ –¢–µ—Å—Ç –° SGR-lite:")
    result = adapter.call_model(
        messages=[{"role": "user", "content": "–ù–∞–ø–∏—à–∏ —Ñ—É–Ω–∫—Ü–∏—é –Ω–∞ Python –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —á–µ—Ç–Ω–æ—Å—Ç–∏ —á–∏—Å–ª–∞"}],
        model="yandexgpt-lite",
        sgr_mode="lite"
    )
    
    if result["success"]:
        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ! –õ–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å: {result['latency']:.2f}s")
        print(f"–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç: {result['content'][:300]}...")
    else:
        print(f"‚ùå –û—à–∏–±–∫–∞: {result['error']}")


if __name__ == "__main__":
    test_yandex_gpt()