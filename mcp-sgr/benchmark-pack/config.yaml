# SGR Benchmark Pack Configuration
version: "1.0"

# Models to test
models:
  - id: "qwen/qwen-2.5-72b-instruct"
    name: "Qwen-2.5-72B"
    type: "large"
    cost_per_1k: 0.0003
    
  - id: "deepseek/deepseek-chat"
    name: "DeepSeek-V2.5"
    type: "large"
    cost_per_1k: 0.00014
    
  - id: "google/gemma-2-9b-it"
    name: "Gemma-2-9B"
    type: "small"
    cost_per_1k: 0.0001
    
  - id: "meta-llama/llama-3.2-3b-instruct"
    name: "Llama-3.2-3B"
    type: "small"
    cost_per_1k: 0.00006

# SGR modes
sgr_modes:
  - name: "off"
    description: "Baseline without SGR"
    
  - name: "lite"
    description: "Lightweight structured guidance"
    schema_fields: ["requirements_analysis", "implementation"]
    
  - name: "full"
    description: "Comprehensive structured analysis"
    schema_fields: ["requirements_analysis", "design", "implementation", "testing", "validation"]

# Task categories
categories:
  code_generation:
    count: 20
    distribution:
      easy: 12
      medium: 6
      hard: 2
    metrics: ["pass_rate", "test_coverage", "security_score"]
    
  rag_qa:
    count: 20
    distribution:
      base: 12
      adversarial: 8
    metrics: ["faithfulness", "groundedness", "citation_accuracy", "coverage"]
    rag_enabled: true
    
  summarization:
    count: 10
    distribution:
      single_doc: 6
      comparative: 4
    metrics: ["rouge_score", "bert_score", "groundedness"]
    
  planning_decision:
    count: 10
    distribution:
      architecture: 6
      product: 4
    metrics: ["criteria_completeness", "reasoning_quality", "tradeoff_analysis"]
    
  data_etl:
    count: 10
    distribution:
      cleaning: 6
      transformation: 4
    metrics: ["accuracy", "completeness", "validation_rate"]
    
  agent_workflow:
    count: 10
    distribution:
      code_chain: 6
      rag_agent: 4
    metrics: ["success_rate", "steps_completed", "retry_count"]

# Evaluation settings
evaluation:
  runs_per_task: 3
  temperature: 0.1
  max_tokens: 4000
  timeout: 120
  
  # RAG settings
  rag:
    retrieval_k: 5
    rerank_enabled: true
    coverage_threshold: 0.7
    
  # Metrics thresholds
  thresholds:
    pass_rate: 0.8
    faithfulness: 0.85
    groundedness: 0.9
    coverage: 0.7

# Reporting
reporting:
  formats: ["markdown", "json", "csv"]
  include_artifacts: true
  cost_analysis: true
  latency_percentiles: [50, 95, 99]