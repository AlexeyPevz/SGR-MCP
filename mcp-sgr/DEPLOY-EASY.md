# üöÄ –°–ê–ú–û–ï –ü–†–û–°–¢–û–ï –†–ê–ó–í–ï–†–¢–´–í–ê–ù–ò–ï MCP-SGR

## –í–∞—Ä–∏–∞–Ω—Ç 1: –°–£–ü–ï–†-–ë–´–°–¢–†–´–ô (1 –∫–æ–º–∞–Ω–¥–∞)

```bash
curl -sSL https://raw.githubusercontent.com/mcp-sgr/mcp-sgr/main/deploy-simple.sh | bash
```

–í—Å—ë! –°–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω –Ω–∞ –ø–æ—Ä—Ç—É 8080.

## –í–∞—Ä–∏–∞–Ω—Ç 2: DOCKER (—Ç–æ–∂–µ 1 –∫–æ–º–∞–Ω–¥–∞)

```bash
docker run -p 8080:8080 -e OPENAI_API_KEY=your-key mcp-sgr/mcp-sgr:latest
```

## –í–∞—Ä–∏–∞–Ω—Ç 3: –†–£–ß–ù–û–ô (3 —à–∞–≥–∞)

```bash
# 1. –ö–ª–æ–Ω–∏—Ä–æ–≤–∞—Ç—å
git clone https://github.com/mcp-sgr/mcp-sgr && cd mcp-sgr

# 2. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å
pip install fastapi uvicorn httpx aiohttp pydantic

# 3. –ó–∞–ø—É—Å—Ç–∏—Ç—å
python3 -m src.http_server
```

## üéØ –ß–¢–û –ü–û–õ–£–ß–ê–ï–¢–ï –°–†–ê–ó–£:

### REST API –Ω–∞ –ø–æ—Ä—Ç—É 8080:

```bash
# –¢–µ—Å—Ç —á—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç
curl http://localhost:8080/health

# –ê–Ω–∞–ª–∏–∑ –∑–∞–¥–∞—á–∏
curl -X POST http://localhost:8080/v1/apply-sgr \
  -H "Content-Type: application/json" \
  -d '{"task": "–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å –∫ –ë–î", "schema_type": "analysis"}'
```

## üîß –ú–ò–ù–ò–ú–ê–õ–¨–ù–ê–Ø –ù–ê–°–¢–†–û–ô–ö–ê

### –ï—Å–ª–∏ –µ—Å—Ç—å OpenAI –∫–ª—é—á:
```bash
export CUSTOM_LLM_URL=https://api.openai.com/v1/chat/completions
export OPENAI_API_KEY=sk-...
```

### –ï—Å–ª–∏ –µ—Å—Ç—å Gemini:
```bash
export CUSTOM_LLM_URL=https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent
export GEMINI_API_KEY=...
```

### –ï—Å–ª–∏ –µ—Å—Ç—å –ª–æ–∫–∞–ª—å–Ω—ã–π Ollama:
```bash
export LLM_BACKENDS=ollama
export OLLAMA_HOST=http://localhost:11434
```

## ‚ùì –ß–ê–°–¢–´–ï –í–û–ü–†–û–°–´

**Q: –ù—É–∂–µ–Ω –ª–∏ MCP –∫–ª–∏–µ–Ω—Ç?**
A: –ù–µ—Ç! HTTP API —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –ª—é–±—ã–º —è–∑—ã–∫–æ–º/–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–º.

**Q: –ù—É–∂–Ω–æ –ª–∏ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—Ç—å —Å—Ö–µ–º—ã?**
A: –ù–µ—Ç! –ë–∞–∑–æ–≤—ã–µ —Å—Ö–µ–º—ã —É–∂–µ –≤—Å—Ç—Ä–æ–µ–Ω—ã.

**Q: –†–∞–±–æ—Ç–∞–µ—Ç –ª–∏ –±–µ–∑ GPU?**
A: –î–∞! –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤–Ω–µ—à–Ω–∏–π LLM API.

**Q: –ú–æ–∂–Ω–æ –ª–∏ –≤ production?**
A: –î–ª—è –ø—Ä–æ–¥–∞ –¥–æ–±–∞–≤—å—Ç–µ nginx –∏ systemd (—Å–º. –ø—Ä–∏–º–µ—Ä—ã –Ω–∏–∂–µ).

## üì± –ü–†–ò–ú–ï–†–´ –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø

### –í Python:
```python
import requests

response = requests.post('http://localhost:8080/v1/apply-sgr', 
    json={'task': '–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥', 'schema_type': 'analysis'})
print(response.json())
```

### –í Node.js:
```javascript
fetch('http://localhost:8080/v1/apply-sgr', {
    method: 'POST',
    headers: {'Content-Type': 'application/json'},
    body: JSON.stringify({task: '–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥'})
}).then(r => r.json()).then(console.log)
```

### –í n8n:
–ü—Ä–æ—Å—Ç–æ –¥–æ–±–∞–≤—å—Ç–µ HTTP Request –Ω–æ–¥—É —Å URL: `http://your-server:8080/v1/apply-sgr`

## üö® –ü–†–û–ë–õ–ï–ú–´?

### "Module not found"
```bash
pip install -r requirements.txt
# –∏–ª–∏
pip install fastapi uvicorn httpx aiohttp pydantic
```

### "Connection refused"  
```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω
ps aux | grep http_server
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ—Ä—Ç
netstat -tlnp | grep 8080
```

### "No LLM configured"
```bash
# –î–æ–±–∞–≤–∏—Ç—å –ª—é–±–æ–π LLM
export CUSTOM_LLM_URL=https://api.openai.com/v1/chat/completions
export OPENAI_API_KEY=your-key
```

## üéâ –í–°–Å!

–°–µ—Ä—å–µ–∑–Ω–æ, —ç—Ç–æ –≤—Å—ë —á—Ç–æ –Ω—É–∂–Ω–æ –¥–ª—è –±–∞–∑–æ–≤–æ–≥–æ –∑–∞–ø—É—Å–∫–∞. 
–û—Å—Ç–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ - –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã.